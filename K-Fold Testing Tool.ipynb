{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Testing Tool\n",
    "\n",
    "This is a set of tools that should help to get up to speed when delivering Visual Recognition projects. It provides helpers to simplify the training, testing and evaluation of classifiers.\n",
    "This particular tool helps you to automate k-fold cross validation for IBM Watson Visual Recognition.\n",
    "\n",
    "## Features\n",
    "- K-Fold Cross Validation\n",
    "- Persisting of train, test and result sets\n",
    "\n",
    "## Image Corpus Layout\n",
    "\n",
    "Currently the tooling is working with image corpora that are file and folder based. An image corpus can consist of several folders. Each folder represents a class the respective classifier will be able to recognize. Each class folder  contains all images that will be used to train and test the classifier on this class. If only one class per classifier is given, a folder called negative_examples is needed as well.\n",
    "\n",
    "To get a better understanding of the layout, take a look at this sample folder hierarchy (also contained in this project):\n",
    "\n",
    "```\n",
    " ./corpus\n",
    "     /audi\n",
    "         /athree\n",
    "             3_1.jpg\n",
    "             ...\n",
    "         /afour\n",
    "             a4_1.jpg\n",
    "             ...\n",
    "     /mercedes_corpus\n",
    "         /sclass\n",
    "             sclass_1.jpg\n",
    "             ...\n",
    "         /negative_examples\n",
    "             negative_sclass_1.jpg\n",
    "             ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import sklearn helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# import custom VR tooling libs\n",
    "import vrtool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "\n",
    "When using this tool for the first time, you'll find a file called **dummy.config.ini** which needs to be copied and renamed to **config.ini**.\n",
    "\n",
    "\n",
    "Configure *your* tool by entering your IAM API key and URL of the Visual Recognition service instance.\n",
    "```\n",
    "[vr]\n",
    "IAM_API_KEY:your_IAM_api_key\n",
    "URL:your_service_url\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Overview & Statistics\n",
    "\n",
    "The following section provides an extensive overview of the image corpus and statistics of the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the folder that contains the corpora in your project\n",
    "corpora_folder_name = '../corpus'\n",
    "config_name = 'config.ini'\n",
    "\n",
    "#Load config and setup tool\n",
    "runner = vrtool.Runner(corpora_folder_name, config_name=config_name)\n",
    "\n",
    "# Print a summary of the available corpora in the corpora directory\n",
    "corpora = runner.get_available_corpora()\n",
    "\n",
    "print('\\nAvailable image corpora:')\n",
    "print('\\n'.join('{}: {[0]}'.format(*el) for el in enumerate(corpora)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a detailed overview of the different classes and their distribution within each corpus\n",
    "corpora_info = runner.get_corpora_info(corpora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test / Training Sets\n",
    "\n",
    "In this step the training and test sets for a specific classifier are created in the follwoing steps:\n",
    "1. Determine the corpus to be used by setting the **corpus_to_train** variable to a corpus name in your corpora folder (e.g. bmw)\n",
    "2. Set the number of splits **k** for K-Fold cross validation\n",
    "3. Check if **(k-1) * number of images per class > 10**, otherwise the class won't be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the name of the corpus for which a classifier will be trained\n",
    "corpus_to_train = 'mercedes'\n",
    "\n",
    "# Number of splits k for K-Fold cross validation\n",
    "splits = 4\n",
    "\n",
    "# Select the right corpus based on the value of corpus_to_train and filter out classes \n",
    "# with less than 10 images for training\n",
    "img_info = [el['image_info'] for el in corpora_info if el['corpus_name'] == corpus_to_train ][0]\n",
    "negative_examples = [el['negative_examples'] for el in corpora_info if el['corpus_name'] == corpus_to_train ][0]\n",
    "img_info = img_info.groupby('class_name').filter(lambda x: (splits-1)*len(x) >= 70)\n",
    "\n",
    "print(\"Classifier to be trained:\", corpus_to_train)\n",
    "print(\"Classes to be trained:\", img_info['class_name'].unique())\n",
    "print(img_info.class_name.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiments\n",
    "Training and testing sets for the Stratified K Fold cross validation are created. The stratification is based on the class_name labels in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = runner.create_experiments(splits, img_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataframes\n",
    "\n",
    "All training and testing configurations will be saved as pickle file in the **modelconfiguration** folder referencing the image data used. \n",
    "That allows to reuse the data for retraining, testing or further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_experiments(experiments, corpus_to_train, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier\n",
    "\n",
    "Train the classifier based on the experiments defined in the previous steps. This might take a couple of minutes depending on the number of training images used.\n",
    "\n",
    "Internally the method is creating batches of images which are then zipped and sent to the Visual Recognition API for training.\n",
    "\n",
    "You can also use previously created experiment pickle files to create classifiers by setting the **USE_EXTERNAL_EXPERIMENT_DATA** to **True** and specify the path to the external experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load external experiment data sets for training\n",
    "By deafult this cell does nothing and uses the data set that was created in this notebook.\n",
    "\n",
    "You can also use previously created experiment pickle files to test classifiers by setting the **USE_EXTERNAL_EXPERIMENT_DATA** to **True** and specify the path to the external experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default: False -> use experiments created in this notebook\n",
    "#          True -> use external experiments created earlier\n",
    "USE_EXTERNAL_EXPERIMENT_DATA = False\n",
    "\n",
    "# If True, specifiy external experiment data path (path_to_experiment.pkl)\n",
    "EXTERNAL_EXPERIMENT_PATH='modelconfigurations/YOUR_EXPERIMENT_FILE.pkl'\n",
    "\n",
    "if USE_EXTERNAL_EXPERIMENT_DATA:\n",
    "    with open(EXTERNAL_EXPERIMENT_PATH,'rb') as f:\n",
    "        experiments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = runner.train_k_classifiers(experiments, corpus_to_train, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classifier \n",
    "\n",
    "Performs classifier testing by packaging the image data into several zip files and sending them to the Visual Recognition Service for scoring. \n",
    "\n",
    "Main steps:\n",
    "1. Get the relevant classifier ids to be used for testing\n",
    "2. Perform the tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get classifier Ids\n",
    "Loads all available classifiers and tries to find the ones that match your corpus_to_train and cross validation folds.\n",
    "\n",
    "If more than one classifier per cross validation iteration is found, you will see warnings. \n",
    "You need to interactively select the classifiers for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision = False\n",
    "possible_classifiers = runner.vr_service.get_classifier_ids_by_name(corpus_to_train)\n",
    "# Create empty list for the classifier ids\n",
    "classifier_ids = [None] * splits\n",
    "\n",
    "for class_idx,classifier in enumerate(possible_classifiers):\n",
    "    for idx in range(splits):\n",
    "        if possible_classifiers[class_idx]['name'] == corpus_to_train+'_'+str(idx):\n",
    "            if (classifier_ids[idx] is None):\n",
    "                classifier_ids[idx] = possible_classifiers[class_idx]['classifier_id']\n",
    "            else:\n",
    "                collision = True\n",
    "                print(\"Found collision for classifier \"+corpus_to_train+ \" and fold \"+str(idx)\n",
    "                      +\". Already got \"+ classifier_ids[idx] +\", also found \"\n",
    "                      + possible_classifiers[class_idx]['classifier_id'])\n",
    "            \n",
    "if(collision):\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Multiple classifier ids for the same corpus and split found. \"\n",
    "          +\"Please select and assign the correct classifier ids manually: \")\n",
    "    print(\"Fetching possible classifiers...\")\n",
    "    for idx, current_id in enumerate(classifier_ids):\n",
    "        possible_ids = runner.vr_service.get_classifier_ids_by_name(corpus_to_train+\"_\"+str(idx))\n",
    "        print(\"Possible ids for current iteration:\", possible_ids)\n",
    "        classifier_id = input(\"Provide Classifier ID for iteration \"+str(idx)+\":\")\n",
    "        classifier_ids[idx] = classifier_id\n",
    "        print(\"Fetching next possible classifier IDs\")\n",
    "    print(\"Got the following classifier ids which will be used for testing: \", classifier_ids)\n",
    "    print(' ')\n",
    "\n",
    "else:\n",
    "    print(\"Classifier ID to be used:\", classifier_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier_ids[4] = 'mercedes_0123456789'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load external experiment data set for testing\n",
    "By deafult this cell does nothing and uses the data set that was created in this notebook.\n",
    "\n",
    "You can also use previously created experiment pickle files to test classifiers by setting the **USE_EXTERNAL_EXPERIMENT_DATA** to **True** and specify the path to the external experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If False, use experiments created in previous steps in this notebook\n",
    "USE_EXTERNAL_EXPERIMENT_DATA = False\n",
    "\n",
    "# Otherwise, external experiment data (filename.pkl) will be used from the specified path\n",
    "EXTERNAL_EXPERIMENT_PATH='modelconfigurations/TRAIN_TEST.pkl'\n",
    "\n",
    "if USE_EXTERNAL_EXPERIMENT_DATA:\n",
    "    with open(EXTERNAL_EXPERIMENT_PATH,'rb') as f:\n",
    "        experiments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Tests\n",
    "\n",
    "Test the classifier based on the experiments defined in the previous steps. This might take a couple of minutes (**usually 2-5**) depending on the number of images used for testing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = runner.test_k_classifiers(experiments, classifier_ids, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "In this section the classifier performance is analyzed based on the tests that were performed in the previous steps.\n",
    "A confusion matrix is created to analyze the true & false / positives & negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load external data set for evaluation\n",
    "By deafult this cell does nothing and uses the data set that was created in this notebook.\n",
    "\n",
    "You can also use previously created experiment pickle files to test classifiers by setting the **USE_EXTERNAL_RESULT_DATA** to **True** and specify the path to the external experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If False, use result data from the current test run in this notebook\n",
    "USE_EXTERNAL_RESULT_DATA = False\n",
    "\n",
    "# Otherwise, external result data (filename.pkl) will be used from the specified path\n",
    "EXTERNAL_RESULT_PATH='modelconfigurations/YOUR_EVALUATION_FILE.pkl'\n",
    "\n",
    "if USE_EXTERNAL_RESULT_DATA:\n",
    "    with open(EXTERNAL_RESULT_PATH,'rb') as f:\n",
    "        experiments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match results against expected classification results\n",
    "if not USE_EXTERNAL_RESULT_DATA:\n",
    "    for idx,experiment in enumerate(experiments):\n",
    "        evaluation = runner.merge_predicted_and_target_labels(experiment['test'], results[idx])\n",
    "        experiment['evaluation'] = evaluation\n",
    "\n",
    "    # save evaluation results for further analysis and documentation\n",
    "    with open(\"modelconfigurations/\"+corpus_to_train+\"_result_\"+str(splits)+\"_fold_\" +time.strftime(\"%d-%m-%Y-%H-%M-%S\")+ \".pkl\", \"wb\") as fp:\n",
    "        pickle.dump(experiments, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusion matrix as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract actual and predicted values from evaluation\n",
    "thresholds = [0.7, 0.8]\n",
    "\n",
    "runner.print_experiment_confusion_matrix(experiments, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract actual and predicted values from evaluation\n",
    "thresholds = [0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "runner.print_consolidated_experiment_confusion_matrix(experiments, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classification Report\n",
    "Creates a classification report including the most important metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate view on iterations\n",
    "thresholds = [0.7]\n",
    "\n",
    "runner.print_experiment_classification_report(experiments, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#consolidated classification report\n",
    "thresholds = [0.6, 0.7, 0.8]\n",
    "\n",
    "runner.print_consolidated_experiment_classification_report(experiments, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overall accuracy metric\n",
    "thresholds = [0.7, 0.8, 0.85, 0.9]\n",
    "\n",
    "runner.print_consolidated_experiment_metrics(experiments, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize False Positives & False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "for id,experiment in enumerate(experiments):\n",
    "    ev = experiment['evaluation'].copy()\n",
    "    y_actual, y_pred = runner.get_y_values(experiment['evaluation'], threshold)\n",
    "    \n",
    "    \n",
    "    fpfn = ev[ y_actual!= y_pred ]\n",
    "\n",
    "    image_count = fpfn.shape[0]\n",
    "\n",
    "    fig = plt.figure(figsize=(40,130))\n",
    "\n",
    "    columns = 5\n",
    "    idx = 0\n",
    "\n",
    "    for i, row in fpfn.iterrows():\n",
    "        image = mpimg.imread(row['image_x'])\n",
    "        ax = fig.add_subplot(int(image_count / columns + 1), columns, idx + 1)\n",
    "        ax.set_title(\"is: \"+row['class_name']\n",
    "                             +\"\\n pred: \"\n",
    "                             + row['predicted_class_1']\n",
    "                             +\" \\n file: \"\n",
    "                             +row['image_x'].split('/')[-1]\n",
    "                             +\" \\n score: \"\n",
    "                             +str(row['predicted_score_1']), fontsize=25)\n",
    "        idx = idx +1\n",
    "        ax.imshow(image, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Threshold Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for idx,experiment in enumerate(experiments):\n",
    "    score_list = experiment['evaluation']['predicted_score_1']\n",
    "    scores = scores + list(score_list)\n",
    "\n",
    "print(len(scores))\n",
    "n, bins, patches = plt.hist(scores, 20, normed=0, facecolor='green', alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.zip_helper.clean_up()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
