{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Recognition Tooling\n",
    "\n",
    "This is a set of tools that should help to get up to speed when delivering Visual Recognition projects. It provides helpers to simplify the training, testing and evaluation of classifiers.\n",
    "\n",
    "## Features\n",
    "- Binary classifier traning\n",
    "- K-Fold Cross Validation\n",
    "- Evaluation of binary and multi class classifiers\n",
    "- Persisting of train, test and result sets\n",
    "\n",
    "## Image Corpus Layout\n",
    "\n",
    "Currently the tooling is working with image corpora that are file and folder based. An image corpus can consist of several folders. Each folder represents a class the respective classifier will be able to recognize. Each class folder  contains all images that will be used to train and test the classifier on this class. If only one class per classifier is given, a folder called negative_examples is needed as well.\n",
    "\n",
    "To get a better understanding of the layout, take a look at this sample folder hierarchy:\n",
    "\n",
    "```\n",
    " ./corpora_folder_cars\n",
    "     /bmw_corpus\n",
    "         /three\n",
    "             320.jpg\n",
    "             330.jpg\n",
    "         /five\n",
    "             530.jpg\n",
    "             550.jpg\n",
    "         /seven\n",
    "             750.jpg\n",
    "             760.jpg\n",
    "     /audi_corpus\n",
    "         /athree\n",
    "             a3.jpg\n",
    "         /afour\n",
    "             a4.jpg\n",
    "     /mercedes_corpus\n",
    "         /sclass\n",
    "             s500.jpg\n",
    "         /negative_examples\n",
    "             eclass.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import shutil\n",
    "import configparser\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import sklearn helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# import custom VR tooling libs\n",
    "import vrtool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "\n",
    "When using this tool for the first time, you'll find a file called **dummy.config.ini** which needs to be copied and renamed to **config.ini**.\n",
    "\n",
    "\n",
    "Configure *your* tool by entering your IAM API key and URL of the Visual Recognition service instance.\n",
    "```\n",
    "[vr]\n",
    "IAM_API_KEY:your_IAM_api_key\n",
    "URL:your_service_url\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Overview & Statistics\n",
    "\n",
    "The following section provides an extensive overview of the image corpus and statistics of the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the folder that contains the corpora, currently relative to notebook location\n",
    "corpora_folder_name = '../corpus'\n",
    "config_name = 'config.ini'\n",
    "\n",
    "runner = vrtool.Runner(corpora_folder_name, config_name=config_name)\n",
    "corpora = runner.get_available_corpora()\n",
    "\n",
    "# Print a summary of the available corpora in the corpora directory\n",
    "print()\n",
    "print('Available image corpora:')\n",
    "print('\\n'.join('{}: {[0]}'.format(*el) for el in enumerate(corpora)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a detailed overview of the different classes and their distribution within each corpus\n",
    "corpora_info = runner.get_corpora_info(corpora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test / Training Sets\n",
    "\n",
    "In this step the training and test sets for a specific classifier are created in the follwoing steps:\n",
    "1. Determine the corpus to be used by setting the **corpus_to_train** variable to a corpus name in your corpora folder (e.g. bmw)\n",
    "2. Set the number of splits **k** for K-Fold cross validation\n",
    "3. Check if **(k-1) * number of images per class > 10**, otherwise the class won't be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the name of the corpus for which a classifier will be trained\n",
    "corpus_name = 'CORPUS_TO_TRAIN'\n",
    "\n",
    "# Train / Test split\n",
    "test_ratio = 0.25\n",
    "\n",
    "# Select the right corpus based on the value of corpus_to_train and filter out classes \n",
    "# with less than 10 images for training\n",
    "img_info = [el['image_info'] for el in corpora_info if el['corpus_name'] == corpus_name ][0]\n",
    "img_info = img_info.groupby('class_name').filter(lambda x: len(x) >= 10)\n",
    "\n",
    "print(\"Classifier to be trained:\", corpus_name)\n",
    "print(\"Classes to be trained:\", img_info['class_name'].unique())\n",
    "print(img_info.class_name.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, split_test_data = train_test_split(img_info, test_size = test_ratio, stratify=img_info['class_name'])\n",
    "print(\"Training Set:\")\n",
    "print(\"-------------\")\n",
    "print(train_data.class_name.value_counts())\n",
    "print(\"------------------------------\")\n",
    "print(\"Test Set:\")\n",
    "print(\"---------\")\n",
    "print(split_test_data.class_name.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Export Images for Watson Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_SRC_IMG = True\n",
    "TARGET_FOLDER = './studio_data'\n",
    "\n",
    "def move_img(src_path, target_path, keep_src_img=True):\n",
    "    \n",
    "    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "        \n",
    "    if keep_src_img:\n",
    "        shutil.copyfile(src_path, target_path)\n",
    "    else:\n",
    "        shutil.move(src_path, target_path)\n",
    "        \n",
    "def dump_data_df(data, target_folder, keep_src_img):\n",
    "    for __, row in data.iterrows():\n",
    "        src_img_path = row['image']\n",
    "        target_img_path = os.path.join(target_folder, row['class_name'], row['image_name'] )\n",
    "        move_img(src_img_path, target_img_path, keep_src_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_data_df(train_data, os.path.join(TARGET_FOLDER, corpus_name + \"_train\"), KEEP_SRC_IMG)\n",
    "dump_data_df(split_test_data, os.path.join(TARGET_FOLDER,corpus_name + \"_test\"), KEEP_SRC_IMG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataframes\n",
    "\n",
    "All training and testing configurations will be saved as pickle file in the **modelconfiguration** folder referencing the image data used. \n",
    "That allows to reuse the data for retraining, testing or further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"modelconfigurations/\" + corpus_name + \"_train_\" +time.strftime(\"%d-%m-%Y-%H-%M-%S\")+ \".pkl\")\n",
    "split_test_data.to_pickle(\"modelconfigurations/\" + corpus_name + \"_test_\" +time.strftime(\"%d-%m-%Y-%H-%M-%S\")+ \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier\n",
    "\n",
    "Train the classifier based on the experiments defined in the previous steps. This might take a couple of minutes depending on the number of training images used.\n",
    "\n",
    "Internally the method is creating batches of images which are then zipped and sent to the Visual Recognition API for training.\n",
    "\n",
    "You can also use previously created experiment pickle files to create classifiers by setting the **USE_EXTERNAL_EXPERIMENT_DATA** to **True** and specify the path to the external experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load external experiment data sets for training\n",
    "By deafult this cell does nothing and uses the data set that was created in this notebook.\n",
    "\n",
    "You can also use previously created experiment pickle files to test classifiers by setting the **USE_EXTERNAL_EXPERIMENT_DATA** to **True** and specify the path to the external experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default: False -> use experiments created in this notebook\n",
    "#          True -> use external experiments created earlier\n",
    "USE_EXTERNAL_EXPERIMENT_DATA = False\n",
    "\n",
    "# If True, specifiy external experiment data path (path_to_experiment.pkl)\n",
    "EXTERNAL_EXPERIMENT_PATH='modelconfigurations/DATA.pkl'\n",
    "\n",
    "if USE_EXTERNAL_EXPERIMENT_DATA:\n",
    "    with open(EXTERNAL_EXPERIMENT_PATH,'rb') as f:\n",
    "        experiments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "results = runner.train_classifier_from_data_frame(corpus_name, train_data)\n",
    "\n",
    "print(\"Finished Training after %s seconds.\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classifier \n",
    "\n",
    "Performs classifier testing by packaging the image data into several zip files and sending them to the Visual Recognition Service for scoring. \n",
    "\n",
    "Main steps:\n",
    "1. Get the relevant classifier ids to be used for testing\n",
    "2. Perform the tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get classifier Ids\n",
    "Loads all available classifiers and tries to find the ones that match your corpus_to_train and cross validation folds.\n",
    "\n",
    "If more than one classifier per cross validation iteration is found, you will see warnings. \n",
    "You need to interactively select the classifiers for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_classifiers = runner.vr_service.get_classifier_ids_by_name(corpus_name)\n",
    "classifier_id = possible_classifiers[0]['classifier_id']\n",
    "\n",
    "if(len(possible_classifiers) == 1):\n",
    "    print(\"Classifier ID to be used:\", classifier_id)\n",
    "else:\n",
    "    print(\"Please select the classifier you want to use for testing\")\n",
    "    print(json.dumps(possible_classifiers, indent=2))\n",
    "    print('\\nfirst classifier_id: ', possible_classifiers[0]['classifier_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or select classifier_id manually\n",
    "#classifier_id = 'MANUALLY_SELECTED_ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load external experiment data set for testing\n",
    "By deafult this cell does nothing and uses the data set that was created in this notebook.\n",
    "\n",
    "You can also use previously created experiment pickle files to test classifiers by setting the **USE_EXTERNAL_EXPERIMENT_DATA** to **True** and specify the path to the external experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If False, use experiments created in previous steps in this notebook\n",
    "USE_EXTERNAL_EXPERIMENT_DATA = False\n",
    "\n",
    "# Otherwise, external experiment data (filename.pkl) will be used from the specified path\n",
    "EXTERNAL_EXPERIMENT_PATH='modelconfigurations/FILE.pkl'\n",
    "\n",
    "if USE_EXTERNAL_EXPERIMENT_DATA:\n",
    "    with open(EXTERNAL_EXPERIMENT_PATH,'rb') as f:\n",
    "        experiments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Tests\n",
    "\n",
    "Test the classifier based on the experiments defined in the previous steps. This might take a couple of minutes depending on the number of images used for testing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "split_test_results = runner.test_classifier_with_data_frame(classifier_id, split_test_data)\n",
    "\n",
    "print(\"Finished Testing after %s seconds.\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_result = runner.vr_service.parse_img_results(split_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "In this section the classifier performance is analyzed based on the tests that were performed in the previous steps.\n",
    "A confusion matrix is created to analyze the true & false / positives & negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load external data set for evaluation\n",
    "By deafult this cell does nothing and uses the data set that was created in this notebook.\n",
    "\n",
    "You can also use previously created experiment pickle files to test classifiers by setting the **USE_EXTERNAL_RESULT_DATA** to **True** and specify the path to the external experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If False, use result data from the current test run in this notebook\n",
    "USE_EXTERNAL_RESULT_DATA = False\n",
    "\n",
    "# Otherwise, external result data (filename.pkl) will be used from the specified path\n",
    "EXTERNAL_RESULT_PATH='modelconfigurations/EVAL.pkl'\n",
    "\n",
    "if USE_EXTERNAL_RESULT_DATA:\n",
    "    with open(EXTERNAL_RESULT_PATH,'rb') as f:\n",
    "        experiments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you having existing results you only want to analyze, uncomment the following line and comment the next paragraph\n",
    "#evaluation = pd.read_pickle('your_pickle_result_file.pkl')\n",
    "\n",
    "# match results against expected classification results\n",
    "evaluation = runner.merge_predicted_and_target_labels(split_test_data, split_test_results)\n",
    "\n",
    "# save evaluation results for further analysis and documentation\n",
    "evaluation.to_pickle(\"modelconfigurations/\"+corpus_name + \"_result_\" +time.strftime(\"%d-%m-%Y-%H-%M-%S\")+ \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusioin matrix as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract actual and predicted values from evaluation\n",
    "y_actual = evaluation['class_name']\n",
    "y_actual = y_actual.replace(\"negative_examples\", \"None\")\n",
    "y_actual = y_actual.replace(\"negative_examples\", \"None\")\n",
    "y_actual = y_actual.replace(\"negatives\", \"None\")\n",
    "y_pred = evaluation['predicted_class_1']\n",
    "\n",
    "# create confusion matrix as table\n",
    "pd.crosstab(y_pred,y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Performance for different thresholds\n",
    "# TODO ROC\n",
    "evaluation = runner.merge_predicted_and_target_labels(split_test_data, split_test_results)\n",
    "\n",
    "thresholds = [0.5,0.6,0.7,0.75,0.8,0.85]\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "for threshold in thresholds: \n",
    "    ev = evaluation\n",
    "    ev.loc[ev['predicted_score_1'] < threshold,'predicted_class_1'] = 'None'\n",
    "    y_actual_temp = ev['class_name']\n",
    "    y_actual_temp = y_actual_temp.replace(\"negative_examples\", \"None\").replace(\"negative_example\", \"None\").replace(\"negatives\", \"None\")\n",
    "    y_pred_temp = ev['predicted_class_1']\n",
    "    \n",
    "    print(\"F1 Score:\", threshold, metrics.f1_score(y_actual_temp, y_pred_temp,average='micro'))\n",
    "    print(\"Overall Accuracy:\", threshold ,metrics.accuracy_score(y_actual_temp, y_pred_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusioin matrix as chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot confusion matrix with threshold\n",
    "threshold = 0.8\n",
    "\n",
    "ev = runner.merge_predicted_and_target_labels(split_test_data, split_test_results)\n",
    "ev.loc[ev['predicted_score_1'] < threshold,'predicted_class_1'] = 'None'\n",
    "y_actual_temp = ev['class_name']\n",
    "y_actual_temp = y_actual_temp.replace(\"negative_examples\", \"None\").replace(\"negative_example\", \"None\").replace(\"negatives\", \"None\")\n",
    "y_pred_temp = ev['predicted_class_1']\n",
    "\n",
    "confmatrix = runner.get_confusion_matrix(y_actual, y_pred)\n",
    "\n",
    "runner.plot_confusion_matrix(confmatrix, y_actual, y_pred, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize False Positives & False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "## SET THRESHOLD\n",
    "threshold = 0.8\n",
    "\n",
    "ev = runner.merge_predicted_and_target_labels(split_test_data, split_test_results)\n",
    "ev.loc[ev['predicted_score_1'] < threshold,'predicted_class_1'] = 'None'\n",
    "\n",
    "y_actual_temp = ev['class_name']\n",
    "y_actual_temp = y_actual_temp.replace(\"negative_examples\", \"None\").replace(\"negative_example\", \"None\").replace(\"negatives\", \"None\")\n",
    "y_pred_temp = ev['predicted_class_1']\n",
    "\n",
    "fpfn = ev[ y_actual_temp!= y_pred_temp ]\n",
    "\n",
    "image_count = fpfn.shape[0]\n",
    "\n",
    "fig = plt.figure(figsize=(40,30))\n",
    "\n",
    "columns = 5\n",
    "idx = 0\n",
    "\n",
    "for i, row in fpfn.iterrows():\n",
    "    image = mpimg.imread(row['image_x'])\n",
    "    ax = fig.add_subplot(int(image_count / columns + 1), columns, idx + 1)\n",
    "    ax.set_title(\"is: \"+row['class_name']\n",
    "                         +\"\\n pred: \"\n",
    "                         + row['predicted_class_1']\n",
    "                         +\" \\n file: \"\n",
    "                         +row['image_x'].split('/')[-1]\n",
    "                         +\" \\n score: \"\n",
    "                         +str(row['predicted_score_1']), fontsize=25)\n",
    "    idx = idx +1\n",
    "    ax.imshow(image, aspect='auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Threshold Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = evaluation['predicted_score_1']\n",
    "\n",
    "n, bins, patches = plt.hist(x, 20, normed=0, facecolor='green', alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.zip_helper.clean_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
